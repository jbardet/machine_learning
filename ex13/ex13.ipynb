{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from test_utils import test\n",
    "from typing import NamedTuple, List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the MovieLens dataset, containing 100k movie ratings.\n",
    "The goal is to predict the rating of a (movie, user) pair, given other ratings by this user and of this movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 ratings of 943 users for 1682 movies.\n"
     ]
    }
   ],
   "source": [
    "class Dataset(NamedTuple):\n",
    "    \"\"\"Data container with three arrays of the same length:\"\"\"\n",
    "    movies: np.ndarray\n",
    "    users: np.ndarray\n",
    "    ratings: np.ndarray\n",
    "\n",
    "def load_data() -> Dataset:\n",
    "    \"\"\"Load a sparse matrix from a matlab file and return is as a list of \"\"\"\n",
    "    data = scipy.io.loadmat('movielens100k.mat')[\"ratings\"]\n",
    "    movies, users = data.nonzero()  # indices of available ratings in the matrix\n",
    "    ratings = data[movies, users].A1\n",
    "    return Dataset(movies, users, ratings)\n",
    "\n",
    "dataset = load_data()\n",
    "\n",
    "num_users = np.max(dataset.users) + 1\n",
    "num_movies = np.max(dataset.movies) + 1\n",
    "\n",
    "print(f\"Loaded {len(dataset.ratings)} ratings of {num_users} users for {num_movies} movies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the number of ratings per movie and user\n",
    "\n",
    "It will be too tricky to make predictions for movies and users for which too few ratings are available.\n",
    "Below we will investigate the distribution of how many ratings we have for various users and movies, to evaluate if we need to exclude some users or movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ratings_per_movie(dataset: Dataset) -> Dict[int, int]:\n",
    "    \"\"\"Count the number of ratings available per movie\n",
    "    \n",
    "    Inputs:\n",
    "        dataset: Dataset\n",
    "    \n",
    "    Returns:\n",
    "        counts: a dictionary form movie id (int) -> count (int)\n",
    "    \n",
    "    >>> count_ratings_per_movie(Dataset(np.array([0, 0, 1]), np.array([1, 2, 1]), np.array([1.0, 2.0, 3.0])))\n",
    "    {0: 2, 1: 1}\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    for movie in dataset.movies:\n",
    "        if not movie in counts:\n",
    "            counts[movie] = 0\n",
    "        counts[movie] += 1\n",
    "    return counts\n",
    "\n",
    "def count_ratings_per_user(dataset: Dataset) -> Dict[int, int]:\n",
    "    \"\"\"Count the number of ratings given by a user\n",
    "    \n",
    "    Inputs:\n",
    "        dataset: Dataset\n",
    "    \n",
    "    Returns:\n",
    "        counts: a dictionary form user id (int) -> count (int)\n",
    "    \n",
    "    >>> count_ratings_per_user(Dataset(np.array([0, 0, 1]), np.array([1, 2, 2]), np.array([4.0, 1.0, 2.0])))\n",
    "    {1: 1, 2: 2}\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    for user in dataset.users:\n",
    "        if not user in counts:\n",
    "            counts[user] = 0\n",
    "        counts[user] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `count_ratings_per_movie` passes some basic tests.\n",
      "✅ Your `count_ratings_per_user` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(count_ratings_per_movie)\n",
    "test(count_ratings_per_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_ratings_per_movie = count_ratings_per_movie(dataset)\n",
    "num_ratings_per_user = count_ratings_per_user(dataset)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.5))\n",
    "for ax, ratings, unit in zip(axes, (num_ratings_per_movie, num_ratings_per_user), (\"movie\", \"user\")):\n",
    "    ax.hist(ratings.values())\n",
    "    ax.set_title(f\"# Ratings per {unit} (histogram)\")\n",
    "    ax.set_xlabel(\"# Ratings\")\n",
    "    ax.set_ylabel(\"# Occurences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of movies per user = 20, \n",
      "min # of users per movie = 1.\n"
     ]
    }
   ],
   "source": [
    "print(\"min # of movies per user = {}, \\nmin # of users per movie = {}.\".format(\n",
    "        min(num_ratings_per_user.values()), min(num_ratings_per_movie.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove movies with too few ratings\n",
    "\n",
    "As is typical for real-life data, those distributions have a very long tail. There are some movies that have only one rating. Predictions for those will be very unreliable, so we want to take them out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_movies(dataset: Dataset, min_ratings_per_movie=10) -> Dataset:\n",
    "    \"\"\"Filter a dataset, and keep only movies with a minimum number of reviews\n",
    "    \n",
    "    Inputs:\n",
    "        dataset: Dataset\n",
    "        min_cases: int, the required minimum number\n",
    "        \n",
    "    Returns:\n",
    "        new dataset: Dataset\n",
    "    \n",
    "    >>> test_dataset = Dataset(np.array([0, 0, 1]), np.array([0, 1, 1]), np.array([1.0, 1.0, 1.0]))\n",
    "    >>> remove_rare_movies(test_dataset, 2)\n",
    "    Dataset(movies=array([0, 0]), users=array([0, 1]), ratings=array([1., 1.]))\n",
    "    \"\"\"\n",
    "    num_ratings_per_movie = count_ratings_per_movie(dataset)\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    mask = np.zeros([len(dataset.movies)], dtype=np.bool)\n",
    "    for i, movie in enumerate(dataset.movies):\n",
    "        mask[i] = num_ratings_per_movie[movie] >= min_ratings_per_movie\n",
    "    pruned_dataset = Dataset(dataset.movies[mask], dataset.users[mask], dataset.ratings[mask])\n",
    "    return pruned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `remove_rare_movies` passes some basic tests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp/ipykernel_3772/504137845.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros([len(dataset.movies)], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "test(remove_rare_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97953 ratings left after pruning the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp/ipykernel_3772/504137845.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros([len(dataset.movies)], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "pruned_dataset = remove_rare_movies(dataset)\n",
    "print(f\"There are {len(pruned_dataset.ratings)} ratings left after pruning the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, p_test = 0.1, seed = 1):\n",
    "    \"\"\"\n",
    "    Split a dataset randomly into a train and a test part\n",
    "    \n",
    "    Inputs:\n",
    "        dataset: Dataset\n",
    "        p_test: float\n",
    "            propability (0 < p_test < 1) for a data point to go into the test set\n",
    "        seed: integer\n",
    "        \n",
    "    Returns:\n",
    "        train_dataset: Dataset\n",
    "        test_dataset: Dataset\n",
    "    \n",
    "    >>> split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=0)\n",
    "    (Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])), Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)))\n",
    "    \n",
    "    >>> split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=1)\n",
    "    (Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)), Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])))\n",
    "    \"\"\"\n",
    "    # use this generator (https://numpy.org/doc/stable/reference/random/index.html)\n",
    "    # you should use rng.uniform() once inside this function to match the automatic test case\n",
    "    rng = np.random.default_rng(seed)  \n",
    "    \n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    test_mask = rng.uniform(size=len(dataset.ratings)) < p_test\n",
    "    train_mask = ~test_mask\n",
    "    \n",
    "    movies, users, ratings = dataset\n",
    "    \n",
    "    train_data = Dataset(movies[train_mask], users[train_mask], ratings[train_mask])\n",
    "    test_data = Dataset(movies[test_mask], users[test_mask], ratings[test_mask])\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ The are some issues with your implementation of `split_dataset`:\n",
      "**********************************************************************\n",
      "File \"__main__\", line 15, in split_dataset\n",
      "Failed example:\n",
      "    split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=0)\n",
      "Expected:\n",
      "    (Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])), Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)))\n",
      "Got:\n",
      "    (Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])), Dataset(movies=array([], dtype=int32), users=array([], dtype=int32), ratings=array([], dtype=float64)))\n",
      "**********************************************************************\n",
      "File \"__main__\", line 18, in split_dataset\n",
      "Failed example:\n",
      "    split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=1)\n",
      "Expected:\n",
      "    (Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)), Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])))\n",
      "Got:\n",
      "    (Dataset(movies=array([], dtype=int32), users=array([], dtype=int32), ratings=array([], dtype=float64)), Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])))\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points: 88354\n",
      "Number of test points: 9599\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_dataset(pruned_dataset, p_test=0.1, seed=10)\n",
    "print(\"Number of training points:\", len(train_data.ratings))\n",
    "print(\"Number of test points:\", len(test_data.ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the dataset\n",
    "So far, our data has been represented by a list of ratings. We will look at how we can interpret these ratings in a matrix (movies x users) and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(dataset, num_movies, num_users):\n",
    "    \"\"\"\n",
    "    Construct a dense matrix out of the dataset.\n",
    "    \n",
    "    Input: \n",
    "        dataset: Dataset\n",
    "    \n",
    "    Output:\n",
    "        matrix: np.array of floats: (# movies, # users) -> rating (float) or np.NaN if unavailable\n",
    "    \n",
    "    >>> to_matrix(Dataset(np.array([1, 1, 0]), np.array([0, 1, 0]), np.array([1.0, 3.0, 2.5])), 3, 2)\n",
    "    array([[2.5, nan],\n",
    "           [1. , 3. ],\n",
    "           [nan, nan]])\n",
    "    \"\"\"\n",
    "    m = np.zeros([num_movies, num_users]) * np.NaN  # We want NaNs for unavailable ratings\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    ### HINT: Edit `m` by filling in the available ratings\n",
    "    if len(dataset.ratings) > 0:\n",
    "        m[dataset.movies, dataset.users] = dataset.ratings\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `to_matrix` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(to_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAADgCAYAAAB1o95RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABAaElEQVR4nO29e9xcVXn3/f0lIHKUUyCBBBMhigkCmjQGIxTRFLDUUJGKrZKCfSMW21TDo6Q+T6u+D6+HJkqUIqICoVo5qlAEkVJtkAJpghwMmCaYCJEEAspBUITc1/vHXvvOvuee2bNnZu+ZvWeu7+ezPveetddae809v1mzDte6lswMx3Ecx3EGizG9roDjOI7jON3HOwCO4ziOM4B4B8BxHMdxBhDvADiO4zjOAOIdAMdxHMcZQLwD4DiO4zgDiHcACkDSZZL+b7g+VtKmFvL+SNJfFVc7ZxCQdJOk+TmVNaxnx8kDSRslva3X9Rh0vAPQAeHH+teSdurR8/1L1EdI+k0iDEn6beL1X7RSlpmdaGbLi6prI7wDW37y1Fkor9DPXJJJOqSo8geZHXpdgaoiaTJwNPA08A7g6p5WyKk8ZrZbfC1pI/BXZvbvtekk7WBmL3Wzbk7/kFVnTv/jMwDtczpwJ3AZ0PZUq6S5kn4m6WlJFwBK3DtY0n9IelLSE5K+KWnPcO9fgIOAfws994+G+KslbQnlrZA0vf236JSBeBlJ0sckbQEulbSXpBskbQ2zUDdImpjIMzwqk/SXkn4saUlIu0HSiSnPe72kuyU9K+lK4OWJew2fK+k8ok7xBUGTF4T4ZZIekfSMpNWSji7mP+V0gqQxks6V9FBoc66StHe493JJ3wjxT0n6b0n7N/rM65T9Pkm/CPk/XnNvlqQ7QrmbJV0g6WXh3oqQ7N5Q/rubad/JjncA2ud04JshHC9p/1YLkLQvcC3wv4F9gYeAOckkwKeBA4DXApOATwCY2fuAh4E/MbPdzOxzIc9NwFRgP+DuUD+n+owH9gZeCSwg+u5eGl4fBPwWqNv4Bt4IrCXS2eeAr0tSbaLQ8H4X+JfwvKuBUxJJGj7XzD4O3AZ8KGjyQyHPfwNHhvL+Fbha0stxysbfAicDf0jU5vwa+Odwbz7wCqI2aB/gLOC3KZ/5MJKmAV8G3hfK3QdI/mBvAz5MpM2jgLcCfw1gZseENEeE8q+kde07DfAOQBtIejOR+K4ys9VEP9x/3kZRbwceMLNrzOxF4HxgS3zTzNab2S1m9oKZbQU+T/TlbIiZXWJmz5rZC0SdhSMkvaKNujnlYgj4x6CF35rZk2Z2rZk9b2bPAueRro1fmNlXzWwbsByYANTrtM4GdgTON7MXzewaoh9wANp4Lmb2jZDvJTNbCuwEvKaF9+50hw8AHzezTYn2412SdgBeJPrhPsTMtpnZajN7JmO57wJuMLMVodz/Q6RnAEJZdwZ9bAS+Qoqm2tGgUx/vALTHfOAHZvZEeP2vtLcMcADwSPzCopOZhl9L2k/SFZJ+KekZ4BtEveS6SBor6TNhCu8ZYGO41TCPUxm2mtnv4heSdpH0lTCt+gywAthT0tgG+ZMdy+fD5W510h0A/NJGnhL2iw6ei6RFkh4My1JPEY0kXZPl45XAd8JU/FPAg0Sj8/2JZoRuBq6Q9Kikz0naMWO5te3cc8CT8WtJrw7T+FuCpv4/0tu5ljXo1Mc7AC0iaWfgz4A/DILdQjR9dYSkI1osbjPRlFpctpKviab/DTjczPYA3kvCRiDcS/LnwDzgbUSN7OS46Bbr5ZSP2s96EdEo+o1BG/FUaaef9WbgwJrlgYNaeO6Ieob1/o8RfWf2MrM9iQxnXZPl4xHgRDPbMxFebma/DLNBnzSzacCbgJOIlkFhtDZrqW3ndiGaTYj5MvAzYGrQ1N+Tro+itD9weAegdU4m6hVPI1rXPJJoff42tn8hsvI9YLqkd4Zptr8lWuuN2R34DfCUpAOB/1WT/zHgVTXpXyDqXe9C1JN2+pPdidY+nwqGWv+YU7l3AC8BfytpB0nvBGa18Nx6mnwJ2ArsIOkfgD1yqquTLxcB50l6JYCkcZLmheu3SHpdGGU/Q7QksC3kq/3Ma7kGOEnSm4ONyacY+duzeyjzN5IOBT5Yk7+eporQ/sDhHYDWmQ9camYPm9mWOBAZofxF+CHPRFhCOBX4DNGP9lTg9kSSTwJvIBoxfQ/4dk0Rnwb+d5iyOwe4nGi69pfAA0S7FJz+5HxgZ+AJos/5+3kUama/B94J/CWREdi7Gam7Zs9dRrRu/GtJXySaNr4J+B8ibf6OxHSwUyqWAdcDP5D0LNHn+8ZwbzzRD/kzREsD/0m0JBnnS37mIzCzNcDZREulm4l0lXSOdg7R7OWzwFeBK2uK+ASwPLRzf0ZB2h9ENHKpz3Ecx3GcQcBnABzHcRxnAPEOgOM4juMMIN4BcBzHcZwBxDsAjuM4jjOAeAfAcRzHcQaQvusASDpB0lpJ6yWdmyH9JEk/DJ7K1khaGOL3lnSLpHXh716JPItD+WslHV+nzLGSfiLphhzK2lPSNYoODHpQ0lHtlifpw+E9/lTStxQd8NF23ZztuO5cd0Xh2nJtFYaZ9U0AxhL55X8V8DLgXmBakzwTgDeE692J9itPIzow5dwQfy7w2XA9LZS7EzAlPG9sTZkfIdrzekN43UlZy4mO6yS8pz3bKQ84ENgA7BxeX0W017vtunlw3bnuXFuureqGnlcg1zcTnSR1c+L1YmBxi2VcB8wlOjltQoibAKytVyaRo5OjEq8nArcCxyW+LO2WtUcQuGrq2HJ54cvyCNGJbDsANwB/1G7dPLjuXHeuLddWtUO/LQHEgojZFOIyIWky8HrgLmB/M9sMEP7ul/EZ5wMfJXHaVQdlvYrIheqlYfrta5J2bac8M/slsIToCOHNwNNm9oMO6uZsx3XnuisK15ZrqzD6rQNQ7zCITK4OJe0GXAv8naUfc9nwGZJOAh636IjgTI9tVFZgByJXwF82s9cDzxFNabVTt72IDgqaQnQ6166S3ttB3ZztuO4a18111xmurcZ1c211SL91ADYx8jS9icCjzTIpOtbyWuCbZhb7PX9M0oRwfwLweIZnzAHeIWkjcAVwnKRvtFlWfH+Tmd0VXl9D9OVpp7y3ARvMbKuZvUjk3/1NHdTN2Y7rznVXFK4t11Zh9FsH4L+BqZKmKDp16jSiwy0aIknA14EHzezziVvXEx38Q/h7XSL+NEk7SZpCdIDPSgAzW2xmE81scnj2f5jZe9spK5S3BXhE0mtC1FuJDvlpp7yHgdmKztJWKOvBduvmjMB157orCteWa6s4em2EkHcA3k5k9foQ8PEM6d9MNA10H3BPCG8nOq/6VmBd+Lt3Is/HQ/lric7PrlfusWw3mGm7LKLjhleF+n0X2Kvd8ohOF/wZ8FPgX4isYTt6nx5cd64715Zrq5rBTwN0HMdxnAGk35YAHMdxHMfJgHcAHMdxHGcA8Q6A4ziO4wwg3gFwHMdxnAGkMh0AtXgghuPkgevOKQrX1mAiaaOk+yXdI2lVnfuS9MWgi/skvaGoulSiAyBpLPDPwIlEBzq8R9K0JnkW5Pj83MrKu7yyltUPtKo710k5yqsC/dSmlVkPJdbWW8zsSDObWefeiUQ+CqYCC4AvF1WJSnQAgFnAejP7uZn9nsgj1bwmefL84PMWUVnrVtYvS69oVXeuk3KUVwX6qU0rsx6qqK15wOUWcSewZ+zZMG+q0gHwQxycXuC6c4rCtTW4GPADSasbzFB0TRs7FFFoAWQ6xCH8MxcA7LTTTjNmzpyZi5ejgw46iGZl/eyhxzj04P1zKy+N+x9/jNftt3/bZSXzd1Kvjc9tZPKuk1m9evUTZjaulTpUhKa6K0pz0Pzz6AfNtVperDmg6rprSVu77rrrjE4/wyRlLSvv8totq5G2jn/LLvbEr4bqZRnm7vteWAP8LhF1sZldnHg9x8welbQfcIukn5nZisT97h1a1GtXhFkCbZyJPWPGDOsmk89fYqffdcaouEZpm6XJs16dUPue6gGsshLoJO/Qqu5cc90pP6bKuiu7tvqVLO2ZWWNtveHwl9nvHp2SGlrRJfAJ4JyauK8A70m8XgtMyFpmK6EqSwAtH4jRbQ758J0sn3XJiLgNCxfVTXvACmPOKUvqppm/8sxc69WoDllZ/9lUu6R+p9S661fNxfXsc0qtrX6l9vvSKga8xLbUkIakXSXtHl8Df0R0jkGS64HTw26A2cDTZra5o4o3oBIdADN7CfgQcDPRaU9XmdmatDz3P/5Y03I7bfiSDdX6L8xmaMtUpixbOqLs5DPi69v++Svcfu05ddMlBRqX1Qlzx5yaOe2UZUsZ2jJ1RNxt//yVEa/j+3nUrey0qjvXXESnmovrGdOPmmunTXM6p1ZrrWIY2yw9NGF/4MeS7iU6ifB7ZvZ9SWdJOiukuRH4ObAe+Crw1x1VOo0iphXKEMoyZbZt8yGj4t6md42Kyzo11Q2SdX7TO/+paXoqPBWbZyiz5upRZc2ZDZbuyqKtetRrz6pOI20dcfiO9sQvD0wNVdJlJWYAuk08gmlnJFObZ8z4daPS3vzoPaNGgp2OwhqNLNsZcSbrfMjHHmg5v9M67WquXp56mhvaMjVVc+3gmutvso6Wbxm6OvV+X83cAC/aUGqoEt4BqEMs6GbCTk7HHrDCOOPho1n/hdnAaNEnG8XjDzhyVFm1jWay7CxfoEaN+Yo7pqfmm7/yzFE/IMm61Cs37zVjp33NzV95ZuU0B6M7La658lGvI1l2uqGToSahSgx0ByBrz7SRqJJrlY8eE+3cOGBFtAa0YeEipixbOtyoJhu19V+Y3bCRHNoylWOOWsPt154zXL8sRlWNDKeOOSp9WbG2sa0tp956crNnOo3pleZuGbo6VXNx2d3QXLNy0hpx11z5aKbpVvXQCa3MarXTWTAzft8kVIn+7QC8+NOGU1jxBx83co3SxfGXHnRbw3Liso45ag2XHnQbh3zsgeH4Y45aM9xIx+njH/iH3n3RiPzxM8aMX8elB93WkjiHtkwdZTjVSt4D7tx9+HWt0V8y3aUH3caUZUu59KDbhp/ZqVFNX5GD5mLSNBcTa+72a89J1Vz8N01z9ZYI0kjTXLNGuBXNxUaOrrnOyfJ/q9VAM00MbZnatLPY6VJTK/VphXbqZfTXDEDPjRCKCkUYzRS9v7kTo6ws+7+zlNHOe6RCRi9FBtdcenyjtO2+x0HSXZmNAPuRRtqa/rod7WcPT0gNVdJl/84ABDo1qJuybOnw60M+fGdqvjmnLBmVt1F96k171uuRJnvt9bZ5NSNtxDnnlCVMWbZ0eD02nkpOIx6VJZlx+E4zMldoAKiK5iD7KKjXmssS55SHRnqp1571mla1tA2lhkrR6x5IUSHuMee51Sm5VameB7ba+1m9tGV9Zl5k3WaVFSrU4y0yuOYak7fmzAZLdz4D0F0aaWva63a0e34xMTVUSZd9PwOQx/pTPIJKWsXWK/fgK88aTrt81iUNvbS1MkIswhK3FXsBN7pqnW5pbsPCRa45pxD6aetengwhfs/Y1FAl+r4DkAf1jFxqp402LFw0HNLSQfNp3aJpZeqtXeNCpzOyaC5O55pz8qZTd879zJApNVQJ7wC0Se0oacqypXV7zfVGU7cMXT28Blr0Oli9OjUboTbq/ZdlzW5Qqae5LOnANee0js8CjMYQv7exqaFK9G0HYONzG7v6vA0LF/HQuy8afl3rnz3J3DGnDjt8yTpd3K7RUzs9+UZGXLVb07xxHkkvNJf8jAZBc073GLRZgCztWbQNcExqqBJdr62kSZJ+KOlBSWskLQzxe0u6RdK68HevRJ7FktZLWivp+KzPytqA5WFRPLRl6vB+6uTe2KTzlVhgsee2tDrEPgNi4lFdq+5Xs/Ti6/2I1N6L31+yXnnu7y2abumuHzXXiLw01+hePc2VkW62af1GL2ajGpGlPTPzGYBOeQlYZGavBWYDZ0uaBpwL3GpmU4Fbw2vCvdOA6cAJwIWSmv6XJ+86ObMxUx5GT3EZY8avG9FoJb1gxQLLsvWpUb0aibRRfBYvXMnnPPTui4adryTj4+vlsy4Zvi5zo1yHwnXXr5prRF6aSzr8qajmutKm9SNFDyKKmMUYQqkhC5LGSvqJpBvq3DtW0tOS7gnhH3J/E4GudwDMbLOZ3R2unyU6CvNAYB6wPCRbDpwcrucBV5jZC2a2geiIxFnNnnP/448VPhpLHmUae1hL9jjHjF/X8JCfoS1Th/dE12P5rEta6h03StvsCzZ/5ZnDVtfJusRfnDMePnpE+rljTh2ue5V8hXdDd6657eU0y9dPmutWm+b0nsgGYIfUkJGFRDppxG1mdmQIn+q85vXp6YKFpMnA64G7gP3NbDNEXyhgv5DsQOCRRLZNIa5eeQskrZK0avzQlsxTmO02KrW9y+WzLhm2A4gbwXpbmnb5zl1AdOpZXEa9OmQ5VCX57HokXb82yhe7jt2wcNHwaDJm/WenAdsb6ngd+fZrz6nsdq08deeaG00WzcWW/v2muaK0tXXr1kLr3U8UabwYnQY4NjU0Q9JE4I+BrxVW0az0ygEBsBuwGnhneP1Uzf1fh7//DLw3Ef914JRm5e9z6D7WbZIOVOLrpGOWvB2stOtwJu9z4KmQ44sideeayz9fGmXTXZHackdA3aWRtl512C521fo3pAZgI7AqERbYSB1cA8wAjgVuqH1GiH8SuBe4CZhery55hJ7MAEjaEbgW+KaZfTtEPyZpQrg/AXg8xG8CJiWyTwQebfaMybtOzq2+WV3wnvHw0cMjlKPP/gAwcpR09NkfGJ6yTTu6NeuZ8MtnXZJq+d2orNop4uT2sLi8NPexVaVo3bnmGpeVNlvQD5rrRpvmNCfZnhVBNAOwQ2oAnjCzmYlwcZxf0knA42a2OuUxdwOvNLMjgC8B3y3uDXW/lyzgcuD8mvh/As4N1+cCnwvX04l6QjsBU4CfA2ObPafV0djpd51RyMErjUZgrY6Iso7ktm0+pGnaQZwB6IbuXHON6ecZgG5oy2cAuksjbU0+bFe7/H/emBrSdAl8mqgDuBHYAjwPfKNR+pBnI7BvWpp2Qy9mAOYA7wOOS1g5vh34DDBX0jpgbniNma0BrgIeAL4PnG1m25o9JB6NJUc98cgi2UNMulHNYjHa6OCVRsZVWZ23NBuNjRm/bsRIqZERWe16ajOnLPXu1xuBxXH1Rn37HLpPFQ4DKlx3ZdVclnKbaQ4aGy72QnMl80HRlTatjOSx3l4lh0NmmWYAUvLbYjObaGaTiXaC/IeZvTeZRtJ4SQrXs4hs9Z4s6A31vgddRKjtMWcdzbxN78qULkk8umn0jHiU18ooqIjDU4qCkozEeh1cc91lkHTnMwDdpZG2Xjl9N/vq2jenhqy6JGEDAJwFnBWuPwSsIZoluhN4U5by2gnVclvUArVe2bJaZ6//wuwRI51G10ni7VPJZ8R7sqcsWzo8ykuOgpo5QmnFH3raenEex2+WdO916ehEc0lcc665PPH/ZX4Y5LUNEDP7kZmdFK4vMrOLwvUFZjbdzI4ws9lm9l/FvJs+dgVcbzo2jbihjLclxTS6ri17/WenjXrWGQ8fPcIpSlbjplY9sMVbt+oZWtU7Ta7VKbcy7r0uI51oLolrzjWXJ/6/zA9DHW8DLBN92wG4//HH2s6bddSS9K52yMceGG545688kxV3TB91PGu8377Zc4e2TG26jxq2N6obFi5qaluQLC9ZT8huAd6Il02aWAUbgMKJNdeO97Eqaq5ZmUVqrkrrxnkyKO+7rO/TgCEbkxoqRVFrC70OL5s0ccSaTrO10MnnL7Ftmw9pmK6ZtXZtvtPvOsNOv+uMumu0b9O7RqTPsvaadT25CKvyZjBAa7Fpodeai+OyaKXqmjMbLN312gYgTcu17Vk/0EhbB07fwz675oTUUCVdVqy7kp3X7bc/sH39q3aqspH1dO3pY7UHrUxZtjTzaG3FHdM5+MqzRj33gDt3H35OvbXXVi2747Xf+SvPTB2ZZe1Vx+85+TqNGYfv5DMAFKc5yDZDEM8C1NNc8kCdPDUH6bMBrWgu7XWz9E57tLpcVY9bhq4uxKd/njs98tTLNpQaKkWveyBFhdoec9ooJa/ea/IZZe4RZ61b1nRUqMdbZOi15spM3pozGyzdlXkGoB9ppK0Dpr3CPnn/n6SGKumyb2cAakkbpeTde52ybGlLZea13pXV4Ctr3ap03G8Z6bbmikzfCNfcYOCfS4SRz2mAZWFgOgDdIG7wkw1/lqmnvI6sbLaNy6dN+w/XnON0D0O8ODQ2NVSJge0AZG2YOl2HarSO2gtPZr4dqLe45hyn2vg2wD4ha8O0fNYlDRvudhrUoS1TmTvm1K5NqWWZ6k2bxq295yO69umV5gDXnFMIg/jZDDEmNVSJntVW0lhJP5F0Q3i9t6RbJK0Lf/dKpF0sab2ktZKO73ZdGzXctQ1qlvXQuKwiT6xKkmWqN20at/Ze1Ud0VdFdnpqDyFLbNVcsVdFWnowZv65ruioDZvDi0JjUUCV6WduFwIOJ1+cCt5rZVODW8BpJ04gOTZgOnABcKCnTPEtevdO4nNrRV23je8jHHhiRpvZ+8oty86P3jLiXzJc2yqu9F4+2Gr3XLKOxZL3i6+SWsdrnl9VJR0YK1V1ZNTd3zKmuueIpvE0rI7cMXd3rKnQNQ+4IqNNAdP71rcBxbD8MYS0wIVxPANaG68XA4kTem4Gjmj2jF9tmsh6mMvn8JaPSdnoQS7vOZPKoAxXZ9lK07lxz25+VlU7qUCbd9aO2BplG2tr3tXvbB1a9NzVk0SUwFvhJrJWaewK+CKwH7gPe0Ky8dkOvuivnAx8FhhJx+5vZZoDwd78QfyDwSCLdphDXc2pHJVkPU9mwcNGotK0cxFKPRuu7WaZj4xHY7deek2k6r/Z9V8gV8PlUXHeuufqvS8D5VFxbThZymwGonS1KciIwNYQFwJc7r3d9ut4BkHQS8LiZrc6apU6c1YlD0gJJqySt2rp1a9t1zEqtp7asjdKcU5aU6jzz5BRes+m8Oacs4aF3XzQi7vePbMr6WfaMonRXFc3F6ctCp5rLaxtjHvSLttolqx1KP2AGL9qY1NAMSROBPwa+1iDJPODyMBlxJ7CnpAn5vYvt9GIGYA7wDkkbgSuA4yR9A3gsfpPh7+Mh/SZgUiL/RODRegWb2cVmNtPMZo4bN66o+tfl0dnPZk67y3fuSrXILsPoJv5S147Obr/2nMoYZdVQiO6qorlmuwBccx3Rd9pqhU5nkqqEIV4aGpsagH3jjlsIC2qKOZ/Rs0VJujZD1PUOgJktNrOJZjaZyBDmP8zsvcD1wPyQbD5wXbi+HjhN0k6SphBNi6zMs055GG6t/8JsjjlqzfAoq9UGNTk6i0c33RqxxQ3vlGVLh0P8pT7gzt1HpS/TSDIrZdOda65/NFc2bTnFksET4BNxxy2Ei+O8GWeLMs96d0xRxgVZAnAs2w1m9iEyolkX/u6dSPdx4CEio5oTs5Q9Y8aMzKeZNSOLsVMWX9lx+vikQLPoJK1mZXdCFiOrZB2y+vxO1o8SGWNlCUXpruyai+kHzZmVU3dFaqvM9NtZAY20tdeh+9qf/dcHUkOaLoFPE43oNwJbgOeBb9Sk+QrwnsTrYWPSvIPCA/qOmTNn2qpVq3Irb/7KM90fdgMkrTazmb2uR69xzXWXQdJd3tpy0mmkrb0P3c/eeskpqXmvmXNRJl1KOhY4x8xOqon/Y+BDwNuBNwJfNLNZ2WufnYptWszOxuc25uqlavmsSzLvlW723G5OZ5ZhbXdQcM1FuOacfsWAl2xMamgHSWdJis/xvhH4OdE2wK8Cf51L5evQtx2A3/9saJThUKeNYNpobPmsS4Ybvvi5jRrCZg17q6RZ4aZZS9f+aMTnxqcxd8ypo97X7uxVlW2AheKai2hFc9D8f1RPc4Pkfc5pjyI6ogYMmVJD5rLMfhSP/s3sIjO7KFybmZ1tZgeb2evMrLCpn/5dAjji5bbq3t91/blDW6YyZvy64b/17jV6XUYa1XH+yjNZccd0NixcNFBTsWn0WnNZ7vWL5sCXALpJFXSTJ4209YpD97c3X/zu1Lw3/uGXKqPLvp0B2Pj73RpOi+Y5Tdto9HLGw0ePun/wlWcNX89feWYlvlD13sfQlqksn3UJxxy1plfVKiW91lwc75pz8qYKuukKVswSQK+oVm1b4NnndmbM+HV1p4EaTdPWa1iT+evdT07Rxg1sPFKJ/8YcsMLq5kujnge0Vr2i1cuT/EFKyx/XM1nf+P8Xx+1z6D6+BEA5NZecjs9Tc1nKKFJzZd4WOCgU5QCozDYkeS4BlIIithaUIbxs0kRrRBFbVrZtPmREufF1va1VjbZhtfvcNLK819r6tLrVjBJux+pFcM2NrEcrtLMFcZB0V/ZtgGUiTetZtdlIW7u9en879taPpIYq6bJvZwB23/W3De8VsbVqzPh1I8q99KDbGNoydcSUZSsnrrXy3DSyvNdaV6xJt6tx/npT2GXuqfcC11xEO++11tUvuOac9khzLZ3H99BMqaFK9K0R4G57TbLf/PqR5gmbMOeUJZVwdTl3zKlNfapPWba0EB/qg2SMlcagaS4LRWkOBkt3vTYC7DZZ2rMiaaSt3V493o688PTUvLfP/afK6LJvZwAOPXj/XMq5/dpzMo2Uatc80/LMHXPqqPtZz2ZvRKMvS7JOWRri2hFWp/UaJHqtuTTqaS5Jnp9tp5pL4porB61+Dp1+bkX9+Oehp36aAejbDkArtCuKZMN1wArjmKPWDMcl92jXcvOj9wwbatV7dtKIKyuNrMyzWE3He6qT/tljLj3otuHrvPeSDzJ5aG7DwkVsWLhoRFwrmkvWoUyaS5brmusNtSeWtjp1XlYPlp3XS2wbGpMaKkUvDA+APYFrgJ8RnYl8FLA3cAuR3+xbgL0S6RcTeUVaCxyf5Rl5Gs3kbcCVp0FWs7pl8cueVm4/GQEWrTvXXEQ3NGdWLt1VSVtOcxppa5ep4+0PblqcGsqky2ahV92VZcD3zexQ4AiiL8y5wK1mNpXo4IxzASRNIzphazpwAnChpLHdrOz6z07r5uNaolmPtt215Ljc5AxAH1AZ3ZV1BAWuuQZURltFbd8bCAy2mVJDleh6B0DSHsAxwNcBzOz3ZvYUMA9YHpItB04O1/OAK8zsBTPbQNRrLuRghEbkbZDVS+OWVukXByBV1F2euOaKo2ra6hcD015gfbYE0IvavgrYClwq6SeSviZpV2B/M9sMEP7uF9IfCCRNqzeFOMdpBdedUxSurQHCLD2kIenlklZKulfSGkmfrJPmWElPS7onhH8o6r30ogOwA/AG4Mtm9nrgOcLUWAPqzanU/TdLWiBplaRVW7du7bymA06e7mtLQCG6c805uLYqQR7tmRkMDY1JDU14ATjOzI4AjgROkDS7TrrbzOzIED7VccUb0IsOwCZgk5ndFV5fQ/TleUzSBIDw9/FE+kmJ/BOBR+sVbGYXm9lMM5s5bty4QiqfB1U5yaxqU7FNKER3rjmHAddWVcirPevEFXCwMfxNeLljCD1zxtP1DoCZbQEekfSaEPVW4AHgemB+iJsPXBeurwdOk7STpCnAVGBlN+ra6hnr81eeOWxgU2+rVbzV6Zahq5v6DcjL41mr5QxtmZpp29X8lWdWantWVXSXt+Zi6mmuKAZNc1XRVt604r+hnzw4Dg0pNTRD0lhJ9xB1CG9JdByTHBWWCW6S1Poe3az0YusB0dTHKuA+4LvAXsA+RJay68LfvRPpPw48RLRl5sQsz5gxY0ZTn+V5UuvLPO3ZyS1ZRfiI74Ta+mT5H1KRbS9F68411x7taM6sXLrrhrac7tFIWzsdfIC95tpPpgZgY9BCHBbUK4to6+gPgcNq4vcAdgvXbwfW1cufR+iJyaKZ3WPR1NbhZnaymf3azJ40s7ea2dTw91eJ9OeZ2cFm9hozuynrc/Ka8smybaaRx7PaI01r4+ttqRraMrXhSLDoEVBtfeL/YT/YA3RDd6651ukHzXWrTXN6jGVaAngiaCEOF9ctKtop8iOiraDJ+GcsLBOY2Y3AjpL2LeLtVGvPQo9oZdtMPNVVe3xpMq4ZY8ava5i22/vDk++nSg1y1XHNueaccmJDSg1pSBonac9wvTPwNiLnUck04yUpXM8i+p1+soj34h0A8h3hZD34JK1RzbM+WUaSaQZiSbeufWYU2FP6WXNZSNNc8v245pwknToxyucsgPa3AQITgB9Kug/4byIbgBsknSXprJDmXcBPJd0LfBE4LSxL5E7fdwDi0USaEUqeI5wsxi7NnLJ0Wp9WDW6KPj5z0Bh0zWVppKvkmMgpD506MepU52ZgQ2NSQ3p+u8/MXh+Wig6zsMXPzC4ys4vC9QVmNt3MjjCz2Wb2Xx1VOoW+7gDMX3nm8GiiqCNJk89KPq9eoxz3PuecsmT4fqMpzk6sZpPv9dFj0qekmj3Hp2Bbp1eaa5QGRv4ou+aqSS93QDT7zPrJyr8ZHc4AlAoVNLPQc8p8fnY/nfcOg3Uuexquue4ySLors7b6kUba2ulVE+2A//fs1Lwb3/v3ldFlX88A9Iq4p96oV9zsvPdGVtztkDYTkeX5TrWoquac8lL1zy73+luT0AMkvbNOeKuk/dLyeQcgJ5KNXrzOtGHhorrroWkGUPNXntmWFXcj6p3NnrYONueUJb7uXxHq/dBWVXNOeal6e5Br/a2zXQAF8n7ga8BfhPBV4CPA7ZLe1yiTdwByYsPCRXUb2XrTrs//6RtZcUd95055f9laLa/fpon7Gdec4/QAU3roDUPAa83sFDM7BZhGdO7AG4GPNco0UB2AZlObnU59rv/CbKYsW8rQlqnDo7N600+3X3vOKMOtRlO3WadtW6HZEkUj3DgrfwZNc63immuM/29G0jVDxBIuAQCTzeyxxOvHgVcH51MvNsrUtAMQ/Bb/ew4V7DnNpjZbnfqsFdyGhYvYsHARY8avG25sG42GhrZMHR69TVm2dFTjHE+Lpo2mGo3ompFcomiFbu7J7ifdpVEmzcUUqblWKUJz/aKtKvlI6MYyT9G7boAyLwHcJukGSfMlxedOrAjHUj/VKFPTDoCZbQOel/SK3KraJyQF18pBK3PHnMoZDx89vBe6nnCzTItmEXxVDXhcd/Wp1VxWsmiu1ec3ouyac21lI88RdV8t85RzBuBs4DKiMyleD1wOnG1mz5nZWxplyroE8Dvgfklfl/TFOLRbU0kflrRG0k8lfUvSyyXtLekWSevC370S6RdLWi9praTj231ukcQjsXYpavrq0dnPFlJul3DdpdDpiKcozVXEaMy11YSujKhbpAzHWmtIqaEXhDOMrjGzD5vZ34Xrpt2RrB2A7wH/B1gBrE6ElpF0IPC3wEwzOwwYC5wGnAvcamZTiU7OOjeknxbuTyc6NOFCSWPbeXarNBvJ1DagrTSo8VRqPDVW1JetU49rPR7NDZzu+kFzndIlzQ2ctvqBnnuQbDb67+02wHWSnpb0jKRnJT3TLF+mDoCZLQeuAu40s+Vx6KC+OwA7S9oB2AV4FJgHxGUuB04O1/OAK8zsBTPbAKwHZnXw7Mw0G8nUNqBZG9Tn//SNHLAiUkpeU2Od9IzT8vZyNDeIuitSc3Fa19xgaqtIBmcrp2CoSegNnwPeYWavMLM9zGx3M9ujWaZMHQBJfwLcA3w/vD5S0vXt1NLMfgksAR4GNgNPm9kPgP3NbHNIsxmIHRgcCDySKGJTiKtXzwWSVklatXXr1naq1xV2+c5dTRvhvPz5t+onvnb01UsXn1XQXZU014xB0pxrK1/6ao2/GUNNQm94zMwebDVT1iWATxD1UJ+C6OxrYEqrDwMI62DzQv4DgF0lvTctS524uhMtZnZxfAbzuHHjMtepjH6s85qebbWc2tFXj6eJP0HJdeea67ycHmnuE/SptpwCMTryAxBsQ1ZKujfYjHyyThoFm5T1ku6T9IYMNVsl6UpJ71HCG2CzTFk7AC+Z2dM1ce2udrwN2GBmW83sReDbwJuAxyRNAAh/Hw/pNwGTEvknEk2vtUyjaaq0BmfKsqW5r0l2uo6V949H/H/JUu7cMad20y6g8rprR3OQ/zp4z9dOayiB5iqvrXYoY8ezjHVKQ0PpoQkvAMeZ2RFEFvsnSJpdk+ZEYGoIC4AvZ6jWHsDzwB8BfxLCSc0y7ZChYIjOJv5zYKykqUQGL+0eUfgwMFvSLsBvgbcCq4DngPnAZ8Lf60L664F/lfR5ot71VGBlOw9uZ5qqyNFI2l7sNPKuU/x/qVfu0JapI/Ybd/mHpPK6a3dqtKh18HY1lzcl0FzltdUOZfjsayljnYoiWOb/JrzcMYTajuc84PKQ9k5Je0qaEC8nNSj3jHbqk3UG4G+ILFZfAL4FPAP8XTsPNLO7gGuAu4H7Qx0uJvqSzJW0DpgbXmNma4iMdR4gWq87O+zj7TrJUUi9EUk9D3tpvdsswi/C21crPe4eOxsZeN255gpj4LXltEeGbYD7xrYbISwYkT9yRHUP0YzQLUE/SVqxe/to+Pul5HbWrNtaWz4OOGxX2dXMmm4x6CV+fGb3UBeOZa2C7lxz3SUv3bm2nFoaaWunSZPswEUfTs274cOLMulS0p7Ad4C/MbOfJuK/B3zazH4cXt8KfNTMRm1TlfQnZvZvirz/jaLZzpasuwD+VdIeitwKrgHWSvpfWfIOElVbyyo7rjunKFxbTrt0aAMwjJk9BfyIyBdEksw2Imb2b+Hy+eR21vDD/3yzOmRdApgWescnAzcCBwENjxisOu38kM85ZUlmN61FebPqxV7cgg8kGRjdtau5rGW45kYxMNpycqaDbYCSxoWRP5J2JjIg/VlNsuuB08NugNlE20obrv8HFmeMG0HWDsCOknYk+rJcFyxde+f1uGDaMUqpNfaKHf3Uo9aoKa/GuRd7cQterx0Y3bnmspOT5gZGW05+yJqHJkwAfijpPuC/iWwAbpB0lqSzQpobgZ8TOYj6KvDXDesjnSjpS8CBNev/lwEvNatM1g7ARcAGYFeiE4ZeSWQ0U1mybitqd4TTrGFMPr9blvUVXKLoK931WnNJXHP9pa1eU/YDoHKlA0+AZnafmb3ezA43s8PM7FMh/iIzuyhcm5mdbWYHm9nrzCzN+ONRoh0nv2OkS+vrgaZnTKQaAUr6SPIlUQ95K/Bj4BEza9rD6BVuNNM98jYCrKruXHPdpR3dubacLDTS1ssnTrJJH/pIvSzDrF/8kcKNomuRtGOYxWqJZjMAuyfCbuHvTOAm4F2tPqwqdKM3O1A95tYZSN05XcG15bSP5WcEmDOTJV0j6QFJP49Ds0ypHQAz+2SdsJDIy9VH86p52ah1wtLoxzrL9Ga//dDXWzvedc+JM/J8xqDqLkkRmquqFutprt1lEteW0zElPA0QuJTIY+BLwFuAy4F/aZYpqw3ACMzsV9T3Z10qOm3w4vyNvLIlDbfmnLKkbuMc503eG9oyNdXTWzfXTVv9H9VbO37uqU1tHaPaKlXQXVU1103y0FzexodV0FZVKbEdSFuUdAZgZzO7lWhZ/xdm9gnguGaZ2uoASDoO+HU7ebtJpw1es/zJhuz2a89JteRuZuWd/JJ00zVms/eYHGn1+otcBd1VVXPdpIyaq4K2qkrfufot5wzA7ySNAdZJ+pCkP2X76ZMNSe0ASLo/nEaUDJuIXFo23JowKKz/7LSW0seN2fEHHDlqL/MxR63JrV5JWh1t1U6tJkda3foiu+4a45rrDNeW0xGdbwMsir8DdiE602IGkU+L05tlarYL4JU1UQY8aWbPNS1YuoToNKLHzeywELc3cCUwGdgI/JmZ/TrcWwy8H9gG/K2Z3RziZwCXATsT7Y9caBn8F5fZanbumFNLdzpbJxSwC6CSuiuz5vqRNncBuLacpjTcBXDAJJv8/6TvAlj7qe7vAqhF0g7Au83sm2npmhkB/qImPJzlixK4jNEuDs8FbjWzqcCt4TWSpgGnER3OcQJwYfDPDZFhwwK2H49YW2bluGXo6lGjpKoaaBWB664YXHOuLaczRLlmAII768WSLpD0R8F74IeInAj9WbP8bdkAZMHMVgC/qomeB8SHEywn8sIVx19hZi+Y2Qaiys9SdIb2HmZ2R+ghX57IkytFujSt19DWTuWWxUCr6lRJd93WXK3GXHOtUSVtdZteuITuCeXbBvgvwGuITqH8K+AHwKnAyWY2r1nmHYqt2yj2j30am9lmSbGRwoHAnYl08fGHL4br2vjcKdKlab2GthcuVAeYUuqu25pzCqGU2uo2A9Welcth9KvM7HUAkr4GPAEcZGbPZslc2AxAi9TbfmMp8fULkRYonMG8detWIPs56VlImzKdsmzpiF5ws+nVevfj/Ml65rWtrFncgNKx7nqpuVbTuua6SiHa6ha17ZmznZLNAAx7/zOzbcCGrD/+0MQIsFMkTQZuSBjMrAWODT3lCcCPzOw1wVgGM/t0SHcz8Akio5ofmtmhIf49If8Hmj27F0Yz81eemTryGtoylTHj17kRYMH0SndlNNTqV81Bb3Q3SNpq1p71M420tfP4Sfaq+elGgA98rrERoKRJRMs+44nODrzYzJbVpDkWuI7orAqAb1s4M6BOeduA2IZFRIalz4drM7M90ura7RmA64H54Xo+0ZuM40+TtJOkKUSGMSvD1NqzkmZLEtG2hutqCy0Lzb4sBZ+c5zSmr3WXRqy5fvvxLxF9q61B/fFvRodGgC8Bi8zstcBs4OxgMFrLbWZ2ZAh1f/wBzGysme0Rwu5mtkPiOvXHHwrsAEj6FnAH8BpJmyS9n2iv7VxJ64C54TVmtga4CngA+D5wdpjOAPgg8DUiI5qHiHx2l445pyzJ7MDk5kfvaXg/p7PO26Jenao2dTtIumtFc0NbprrmOmSQtOU0ppMlADPbbGZ3h+tngQfpoQ1IYUaAZvaeBrfe2iD9ecB5deJXAYflVa8py5YW4tDm9mvPGdEYpz1jzPh1bFjY+F6ZqNoooIy6c821Rlk1V0ZtOT0gp1XzsJz0euCuOrePknQv0XG/54QOZe6UxQiwaxTpzS6rJWy9w03KQN+57CwJrrnGuOacKtFs+j8sAewbG2+GsGBUOdJuwLXA35nZMzW37wZeaWZHAF8CvlvU++n2NkDHcXqA2wA4Tk40nwF4Is04VdKORD/+3zSzb48qPtEhMLMbJV0oaV8ze6LNGjdk4GYAykCWxrjXB+84juM4o+nEBiAYfn4deNDMPt8gzfiQDkmziH6nn8z3XUQMVAdgyrKlPTV4aoVWp0Y7OT/eKY4qaa5VXHPOwNG5J8A5RAf1HCfpnhDeLuksSWeFNO8CfhpsAL4InGYF7dcfqA7AhoWLemrwFDeMWRxstGoJneX8eKf7uOYcp8/o4DhgM/uxmcnMDk9s87vRzC4ys4tCmgvMbLqZHWFms83sv4p6K24D0EXihnGX79Qz+hxJWS2hnWrhmnOcfOmBt7/CGKgZgLJQJYOssu7JdlrDNec4+VCm0wA7xTsALdBPDVPWdVofFfYW15zjlAgjcuCbFiqELwG0QD81TL5OWw1cc45THkT1Rvlp+AxAF6myNXiV6z7IVPlzq3Ldnf5FQ5YaqoR3AAqk1vta2VyutkKV6z5IuOYcp0A63wZYKoo8DOgSSY9L+mki7p8k/UzSfZK+I2nPxL3FktZLWivp+ET8DEn3h3tfjB0kVIFGhldldcvaDwy67qpk7Fc1Bl1bTqCDbYBlo8gZgMuAE2ribgEOM7PDgf8BFgOE4xBPA6aHPBdKGhvyfBlYQHSc5tQ6ZXaNvBycFNFIu/OVYS6jj3RX5s+1zHUriMvoI2057eEzABkwsxXAr2rifmBmL4WXdwITw/U84Aoze8HMNhAdkzlL0gRgDzO7I3hCuhw4uag6NyMvI6YiZgB6YWBVRgv1ftOda24kvdRcv2nLaYNshwFVhl7aAJzJ9nOwDwQeSdzbFOIODNe18XWRtCA+gWnr1q05V7cYyj6KSqtfRS3Uc9Wday5/Kqy5gddWvyN8BqBjJH0ceAn4ZhxVJ5mlxNfFzC42s5lmNnPcuHGdV7QgkksAZd8aVfb6tUIRunPN5U/Z61ePQdbWwGGWHipE1zsAkuYDJwF/kTjgYBMwKZFsIvBoiJ9YJ750TFm2dMT0ZLOpynqjnG5Nb5Z9BFgE/ag711w56EdtOQ3wXQDtI+kE4GPAO8zs+cSt64HTJO0kaQqRYcxKM9sMPCtpdrCUPR24rpt1zsqGhYtGTE82m6qsN8rp1vRmFUdYndCvunPN9Z5+1ZbTGG1LD6l5pUmSfijpQUlrJC2sk0Zhd8j6sLvkDUW9lyK3AX4LuAN4jaRNkt4PXADsDtwSjkGMTz9aA1wFPAB8HzjbzOJ/5QeBrxEZ0TzE9jW2yuLbAIvDdecUhWvLgY6NAF8CFpnZa4HZwNlhx0iSE9m+Q2QB0a6RQijMFbCZvadO9NdT0p8HnFcnfhVwWI5V6zm+V7s4XHdOUbi2nGgJoP11/jADtDlcPyvpQSIj0AcSyeYBl4flpDsl7SlpQsibK+4JsAXS1jGnLFuaeZ2zmzMAna699vPabRVoprmsuOacVvHPoQHNHQHtG+/eCGFBvWIkTQZeD9Se1d1oB0nuyCpmtZiVmTNn2qpVq3pdjYFA0mozm9nrevQa11x3GSTduba6SyNt7b7nRDvy2FHL9iP48XUfbapLSbsB/wmcZ2bfrrn3PeDTZvbj8PpW4KNmtrrFt9EUPw3QcRzHcTLSqbMfSTsC1wLfrP3xDzTaQZI7vgSQEz5d5jiO0/90sg0w7Pz4OvCgmX2+QbLrgdPDboDZwNNFrP+DzwDkRivbnOaOOdUNAR3HcaqGAds6mgKYA7wPuF/SPSHu74GDAMzsIuBG4O1Eu0SeB87o5IFpeAfAcRzHcTLSyRJAWNdPPf0xWP+f3f5TsuMdgB7go3/HcZxq0sk2wLLhHQDHcRzHycL2rX59gXcAHMdxHCcDAtSZDUCp8F0APcBdATuO41QTmaWGKlHkWQCXSHpc0k/r3DtHkknaNxG3OBx+sFbS8Yn4GZLuD/e+GLZRVBq3ASgO151TFK4tBzMYahIqRJEzAJcBJ9RGSpoEzAUeTsRNA04Dpoc8F0oaG25/mehAhPhwhFFlOqOZc8qStu71AZfhunOK4TJcWwOPhiw1VInCOgBmtgL4VZ1bXwA+ykhTinnAFWb2gpltINr/OEvSBGAPM7sjbI24HDi5qDr3E7dfe05b96qO684pCteWEx0G1L4joLLRVRsASe8Afmlm99bcanT4wYHhuja+0swdcyrzV57Z62oMDK4711xRuLYGEF8CaB1JuwAfB/6h3u06cZYS3+gZC+ITmLZu3dpeReuQ1c1vcmq9nqFfXM4tQ1ezfNYl+VSuYKr+o1G07lxz+VMVzVVVW05nuBFgexwMTAHulbSR6ICDuyWNp/HhB5vCdW18XczsYjObaWYzx40bl1vFs7j5nXPKkhFT6/UM/eJyqrQLoCo/GikUqruqaK5KVEhzldRW3lSpPeuY2BVwWqgQXesAmNn9ZrafmU02s8lEX4Q3mNkWosMPTpO0k6QpRIYxK8MBCM9Kmh0sZU8HrutWnVuhlXX1Xu0CGMQDi/pZd/1sy1EF+llbrTBIu5pE+ujfZwACkr4F3AG8RtImSe9vlNbM1gBXAQ8A3wfONrNt4fYHga8RGdE8BNxUVJ27xdwxp/bkx7iKo8FWcd05ReHacgAYGkoPTUjbThruHyvpaUn3hFBviSkXCvMEaGbvaXJ/cs3r84Dz6qRbBRyWa+V6zCD1mLuN684pCteWgwGdW/pfBlxAtAOkEbeZ2UkdP6kJ7gmwi1TFuMlxHMepj4aGUkMzUraTdh3vAHSRChk3OY7jOLWYZVkC2DfevRHCgjaedJSkeyXdJGl6zu9iGO8A9AifDXC6jWvOcXJgqEmAJ+LdGyFc3OIT7gZeaWZHAF8CvptTzUfhHYAe4bMBTrdxzTlO53S6BNAMM3vGzH4Trm8EdkyeMZEn3gHoAe6Vzek2rjnHyQGjcE+AksbHB0RJmkX0O/1kxwXXobBdAE5jfBeA021cc46TB5Zpq18aYTvpsUS2ApuAfwR2BDCzi4B3AR+U9BLwW+C0cG5E7ngHoCDmrzxz1JTr0JapjBm/rkc1chzHcTqmw9/iDNtJLyDaJlg43gEoiHrrrf7j7ziOU2HMYNu25ukqgtsA9ICB8p3tOI7TLxiwbSg9VAifAegBB9y5e6+r4DiO47RDxfz9p1HkWQB1/R1L+htJayWtkfS5RPxiSevDveMT8TMk3R/ufTG2jqwyj85+ttdV6Ftcd05RuLacYSPADs4CKBNFLgFcBpyQjJD0FmAecLiZTQeWhPhpwGnA9JDnQkljQ7YvAwuITtOaWlum49RwGa47pxguw7U12BjeAchCA3/HHwQ+Y2YvhDSPh/h5wBVm9oKZbSA6JWuWpAnAHmZ2R9gGcTlwclF1dqqP684pCteWA3gHoANeDRwt6S5J/ynpD0L8gcAjiXSbQtyB4bo2vtL4nuyu47pzisK1NVA0cQKUgyOgbtJtI8AdgL2A2cAfAFdJehVQbw3MUuLrEg5dWABw0EEHdVxZp28oTHeuuYHHtTVIGJhvA2ybTcC3LWIl0dEJ+4b4SYl0E4FHQ/zEOvF1MbOL4wMYxo0bl3vlncpSmO5ccwOPa2uQiP0ApIUK0e0OwHeB4wAkvRp4GfAEcD1wmqSdJE0hMoxZaWabgWclzQ6WsqcD13W5zk71+S6uO6cYvotra7AwSw8VorAlgAb+ji8BLgnbaH4PzA+GMGskXQU8ALwEnG1mcVfqg0TWtzsDN4XgOHVx3TlF4dpywPpqCaCwDkCKv+P3Nkh/HnBenfhVwGE5Vs3pY1x3TlG4tpzh0wA7QNIlwEnA42Y2SgdhZmgZ8HbgeeAvzezujh7aAHcF7DiO4zgZMCIjwLSQgctI9/1wItt9RCwg8htRCN4BcBzHcZwsmIENpYemRdT1J5FkHnB5MCy9E9gz+I/IHT8LwHEcx3Ey0gUbgEY+JDbn/aC+7QCsXr36N5LW5lTcvkSWvXmRZ3llKOuVOT2/0uSsOSjHZ1t0WZ2UNzC6W7169ROSnqOcn2FZ9JBnWXW19Sy/vvnf7Zp9m+R9uaRVidcXm9nFLTy7Jf83ndC3HQBgrZnNzKMgSavyKivv8spa1oCSm+agvJ9tmb8P/YqZjSvrZ1hmPeRdNzPrxrkNjXxI5I7bADiO4zhOebgeOF0Rs4Gng/+I3OnnGQDHcRzHKRUN/EnsCGBmFwE3Em0BXE+0DfCMourSzx2AVtZcci9LkgHfMLP3hdc7EBlx3NVmeWcBz5vZ5Z3WLYU8yxpE8v7/tVReRTVXRHn9Ss++613UVst1a0LptJXiTyK+b8DZ3aiLrGKuC6uCpN8A64A3mdlvJZ0IfBrYZGYn9bZ2Tj/imnOKwrXVn7gNQLHcBPxxuH4P8K34hqS9JX1X0n2S7pR0uKQxkjZK2jORbr2k/SV9QtI5Ie5gSd+XtFrSbZIO7eabckqNa84pCtdWn+EdgGK5guhAkJcDhxNNl8V8EviJmR0O/D2R44chooNB/hRA0huBjWb2WE25FwN/Y2YzgHOAC4t9G06FcM05ReHa6jP62Qag55jZfZImE/WWb6y5/WbglJDuPyTtI+kVwJXAPwCXAqeF18NI2g14E3B15DIagJ2Keg9OtXDNOUXh2uo/vANQPNcDS4isPvdJxDdy9nAHcIikccDJwP+tSTMGeMrMjsy7ok7f4JpzisK11Uf4EkDxXAJ8yszur4lfAfwFgKRjgSfM7JlgAfod4PPAg2b2ZDKTmT0DbJB0asgrSUcU+xaciuGac4rCtdVHeAegYMxsk5ktq3PrE8BMSfcBnwHmJ+5dSXTE6JV18kH0RXu/pHuBNUSHRzgO4JpzisO11V/4NkDHcRzHGUB8BsBxHMdxBhDvADiO4zjOAOIdAMdxHMcZQLwD4DiO4zgDiHcAHMdxHGcA8Q6A4ziO4wwg3gFwHMdxnAHEOwCO4ziOM4D8/7kdRtkY6ToxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(8, 3))\n",
    "for ax, label, data in zip(axes, (\"All data\", \"Train data\", \"Test data\"), (dataset, train_data, test_data)):\n",
    "    im = ax.matshow(to_matrix(data, num_movies, num_users))\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel(\"Movie\")\n",
    "    ax.set_ylabel(\"User\")\n",
    "fig.colorbar(im, label=\"Rating\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing predictors\n",
    "\n",
    "The goal of recommender systems is to fill in those matrices. In the remainder of this Notebook, we will implement different methods of making those predictions. Let's first develop the tools to compare them.\n",
    "\n",
    "Our prediction methods will all have the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, train_data: Dataset):\n",
    "        # This is where you can do any preparation or 'training' if necessary.\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, test_data: Dataset):\n",
    "        \"\"\"\n",
    "        Make predictions for the users and movies in the test dataset \n",
    "        (without looking at the ratings).\n",
    "        \n",
    "        Inputs:\n",
    "            test_data: Dataset (with `n` entries)\n",
    "        \n",
    "        Output:\n",
    "            predictions: np.array of floats, shape (`n`)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You would use a predictor like this as follows:\n",
    " \n",
    " ```\n",
    " p = Predictor(train_data)  # this initializes the model. This may include training.\n",
    " predictions = p(test_data)  # this calls `__call__` and makes a prediction.\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, a predictor that recommends the same rating everywhere would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMeanPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Always predict the mean rating from the training set\n",
    "    \n",
    "    >>> train_data = Dataset(np.array([1, 2, 3, 4]), np.array([1, 2, 3, 4]), np.array([1.0, 2.0, 2.0, 5.0]))\n",
    "    >>> test_data = Dataset(np.array([1, 2, 3, 4]), np.array([2, 1, 4, 0]), np.array([4.0, 1.0, 1.0, 2.0]))\n",
    "    >>> mean_predictor = GlobalMeanPredictor(train_data)\n",
    "    >>> mean_predictor(test_data)\n",
    "    array([2.5, 2.5, 2.5, 2.5])\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ ENTER YOUR CODE HERE ___ ###\n",
    "        ####################################\n",
    "        self.mean = train_data.ratings.mean()\n",
    "\n",
    "    def __call__(self, test_data: Dataset):\n",
    "        return np.full_like(test_data.ratings, fill_value=self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `GlobalMeanPredictor` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(GlobalMeanPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the predictions using Mean Squared Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(predictions, real_ratings):\n",
    "    \"\"\"Compute the mean squared prediction error\n",
    "    \n",
    "    Inputs:\n",
    "        predictions: np.array of floats, shape (n)\n",
    "        real_ratings: np.array of floats, shape (n)\n",
    "    \n",
    "    Returns:\n",
    "        mean squared error: float\n",
    "    \n",
    "    >>> mse(np.array([1., 1.2, 2.]), np.array([2., 1., 1.5]))\n",
    "    0.43\n",
    "    >>> mse(np.array([4., 2., 1.]), np.array([4., 3., 1.]))\n",
    "    0.3333333333333333\n",
    "    \"\"\"\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    return np.mean((predictions - real_ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `mse` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error for the global mean predictor can now be computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2454544657178057"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_global_mean = GlobalMeanPredictor(train_data)\n",
    "\n",
    "mse(predict_global_mean(test_data), test_data.ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good to include simple baselines like this one in your machine learning experimentation. We now know that we should at least beat an MSE of `1.24` on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now gradually make the baseline predictor more complex, by differentiating between users. The idea is that some users will give higher scores on average than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User's mean prediction\n",
    "\n",
    "Here, to predict the score for a tuple `(movie, user)`, we will return the  average all movie ratings of the `user`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMeanPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Predict the mean rating of the user we are predicting for.\n",
    "    \n",
    "    >>> train_data = Dataset(np.array([1, 2, 3, 4]), np.array([1, 2, 2, 0]), np.array([1.0, 2.0, 2.5, 5.0]))\n",
    "    >>> test_data = Dataset(np.array([1, 2, 3, 4]), np.array([2, 1, 1, 0]), np.array([4.0, 1.0, 1.0, 2.0]))\n",
    "    >>> mean_predictor = UserMeanPredictor(train_data)\n",
    "    >>> mean_predictor(test_data)\n",
    "    array([2.25, 1.  , 1.  , 5.  ])\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        # Hint: don't worry about making this part fast.\n",
    "        unique_users = np.unique(train_data.users)\n",
    "        self.ratings = np.zeros([np.max(unique_users) + 1]) * np.NaN\n",
    "        for user in unique_users:\n",
    "            self.ratings[user] = np.mean(train_data.ratings[train_data.users == user])\n",
    "\n",
    "    def __call__(self, test_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        return self.ratings[test_data.users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `UserMeanPredictor` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(UserMeanPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this working better than predicting the global mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.082106040332895"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_user_mean = UserMeanPredictor(train_data)\n",
    "\n",
    "mse(predict_user_mean(test_data), test_data.ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Why would always predicting the user's mean be pretty useless in practice?\n",
    "\n",
    "Q: If you want, you can improve the predictor by falling back to the global mean in case we haven't seen any ratings of a user before (or not enough of them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie's mean prediction\n",
    "\n",
    "Here, to predict the score for a tuple `(movie, user)`, we will return the  average all movie ratings of the `movie`. \n",
    "\n",
    "Under what assumption is this a good model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieMeanPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Predict the mean rating of the movie, irrespective of the user\n",
    "    \n",
    "    >>> train_data = Dataset(np.array([0, 0, 1, 1, 2]), np.array([1, 2, 3, 4, 5]), np.array([4.0, 1.0, 1.0, 2.0, 1.0]))\n",
    "    >>> test_data = Dataset(np.array([0, 1, 2, 1]), np.array([1, 2, 2, 0]), np.array([1.0, 2.0, 2.5, 5.0]))\n",
    "    >>> mean_predictor = MovieMeanPredictor(train_data)\n",
    "    >>> mean_predictor(test_data)\n",
    "    array([2.5, 1.5, 1. , 1.5])\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        # Hint: don't worry about making this part fast.\n",
    "        unique_movies = np.unique(train_data.movies)\n",
    "        self.ratings = np.zeros([np.max(unique_movies) + 1]) * np.NaN\n",
    "        for movie in unique_movies:\n",
    "            self.ratings[movie] = np.mean(train_data.ratings[train_data.movies == movie])\n",
    "\n",
    "    def __call__(self, test_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        return self.ratings[test_data.movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `MovieMeanPredictor` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(MovieMeanPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0125633530609897"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_movie_mean = MovieMeanPredictor(train_data)\n",
    "\n",
    "mse(predict_movie_mean(test_data), test_data.ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization\n",
    "\n",
    "With those baselines, we can implement a more realistic recommendation model that using Matrix Factorization.\n",
    "\n",
    "- To each movie $i$ in the dataset, we will assign a $d$-dimensional trainable ‘representation vector’ $\\mathbf{m}_i$.\n",
    "- To each user $j$ in the dataset, we will assign a $d$-dimensional trainable ‘representation vector’ $\\mathbf{u}_j$.\n",
    "- You can summarize those representations in two matrices: $\\mathbf{M}$ of size `(#movies, d)`, and $\\mathbf{U}$ of size `(#users, d)`.\n",
    "- The predicted score we will give for a movie $i$ and a user $j$ will be the dot product $\\mathbf{m}_i \\cdot \\mathbf{u}_j$.\n",
    "- You can simultaneously express the predicted scores for all movies and all users as a matrix of size `(#movies, #users)` as the matrix product $\\mathbf{M} \\mathbf{U}^\\top$. This interpretation gives the name to this model.\n",
    "- Given a training set $T$ with rating triples `(movie i, user j, rating r)`,\n",
    "  we will optimize the mean squared prediction error $\\frac{1}{|T|}\\sum_{(i, j, r) \\in T} (\\mathbf{m}_i \\cdot \\mathbf{u}_j - r)^2$ over the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Predict the rating of a user/movie pair as the dot-product \n",
    "    of representation vectors of the user and the movie.\n",
    "    \n",
    "    >>> train_data = Dataset(np.array([0, 0, 1, 1, 2]), np.array([1, 2, 3, 4, 5]), np.array([4.0, 1.0, 1.0, 2.0, 1.0]))\n",
    "    >>> test_data = Dataset(np.array([0, 1, 2, 1]), np.array([1, 2, 2, 0]), np.array([1.0, 2.0, 2.5, 5.0]))\n",
    "    >>> mean_predictor = MatrixFactorizationPredictor(train_data)\n",
    "    >>> mean_predictor(test_data)  # the factorization is not yet optimized here\n",
    "    array([ 2.62654714, -2.89866225,  0.70909287,  5.29901482])\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data: Dataset, num_features=20, seed=1):\n",
    "        # Randomly initialize features for the users and the movies from N(0, 1)\n",
    "        \n",
    "        # use this generator (https://numpy.org/doc/stable/reference/random/index.html)\n",
    "        # you are expected to use rng.normal() twice in this function to match the tests, once for movies, and then once for users\n",
    "        rng = np.random.default_rng(seed)  \n",
    "        \n",
    "        num_movies = np.max(train_data.movies) + 1\n",
    "        num_users = np.max(train_data.users) + 1\n",
    "        ####################################\n",
    "        ### ___ ENTER YOUR CODE HERE ___ ###\n",
    "        ####################################\n",
    "        self.movie_features = rng.normal(size=[num_movies, num_features])\n",
    "        self.user_features = rng.normal(size=[num_users, num_features])\n",
    "        \n",
    "        # Normally, you should train the model here, but we will skip this\n",
    "        # for now, to be able to take it step-by-step.\n",
    "        \n",
    "    def __call__(self, test_data: Dataset):\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        user_features = self.user_features[test_data.users]\n",
    "        movie_features = self.movie_features[test_data.movies]\n",
    "        return (user_features * movie_features).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `MatrixFactorizationPredictor` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(MatrixFactorizationPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without training, the `MatrixFactorizationPredictor` would not perform so well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.84973825903476"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_global_mean = MatrixFactorizationPredictor(train_data)\n",
    "\n",
    "mse(predict_global_mean(test_data), test_data.ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the factorization using SGD\n",
    "\n",
    "One way to optimize the representation vectors for movies and users, is to sample terms from the following loss function:\n",
    "\n",
    "$$\\frac{1}{|T|}\\sum_{(i, j, r) \\in T} (\\mathbf{m}_i \\cdot \\mathbf{u}_j - r)^2$$\n",
    "\n",
    "and optimize the sampled $\\mathbf{m}_i$ and $\\mathbf{u}_j$ using a stochastic gradient descent step.\n",
    "\n",
    "To improve generalization, we will add L2 regularization (also known as `weight decay`) to this model, both for the movie representations as well as for the user representations. Because those weights are unique for each movie / user, you should also sample those stochastically. If you sample a triple `(i, j, r)`, you should minimize:\n",
    "\n",
    "$$ (\\mathbf{m}_i \\cdot \\mathbf{u}_j - r)^2 + \\lambda_\\text{movie} \\left\\lVert\\mathbf{m}_i\\right\\rVert^2 + \\lambda_\\text{user} \\left\\lVert\\mathbf{u}_j\\right\\rVert^2$$\n",
    "\n",
    "You should start by computing a gradient for this term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error after epoch 1: 1.1808808294056248\n",
      "Test error after epoch 1: 1.8869590314229376\n",
      "Train error after epoch 2: 0.9166156001853201\n",
      "Test error after epoch 2: 1.2705102612229386\n",
      "Train error after epoch 3: 0.9053035499844204\n",
      "Test error after epoch 3: 1.1486573296179803\n",
      "Train error after epoch 4: 0.8836613431939891\n",
      "Test error after epoch 4: 1.068041384729876\n",
      "Train error after epoch 5: 0.8824007321729037\n",
      "Test error after epoch 5: 1.035310654227497\n",
      "Train error after epoch 6: 0.8907092057445303\n",
      "Test error after epoch 6: 1.0250016856081683\n",
      "Train error after epoch 7: 0.889327119188381\n",
      "Test error after epoch 7: 1.0100841109970686\n",
      "Train error after epoch 8: 0.8943599556048897\n",
      "Test error after epoch 8: 1.0051513208467266\n",
      "Train error after epoch 9: 0.8966717673413065\n",
      "Test error after epoch 9: 1.001766602615388\n",
      "Train error after epoch 10: 0.8952963806389901\n",
      "Test error after epoch 10: 0.9926906967613117\n",
      "Train error after epoch 11: 0.8924479075693423\n",
      "Test error after epoch 11: 0.9870388059171008\n",
      "Train error after epoch 12: 0.8912534815192307\n",
      "Test error after epoch 12: 0.9830367719275612\n",
      "Train error after epoch 13: 0.8957736489802736\n",
      "Test error after epoch 13: 0.9863704296048056\n",
      "Train error after epoch 14: 0.8964603532778419\n",
      "Test error after epoch 14: 0.9849784010141678\n",
      "Train error after epoch 15: 0.8950688580459725\n",
      "Test error after epoch 15: 0.979792586053537\n",
      "Train error after epoch 16: 0.8972570310729093\n",
      "Test error after epoch 16: 0.979817198260316\n",
      "Train error after epoch 17: 0.8935859340739032\n",
      "Test error after epoch 17: 0.9765124111364518\n",
      "Train error after epoch 18: 0.8957247978855616\n",
      "Test error after epoch 18: 0.9762914961904089\n",
      "Train error after epoch 19: 0.8972484458980335\n",
      "Test error after epoch 19: 0.9769053564836304\n",
      "Train error after epoch 20: 0.8984044394145044\n",
      "Test error after epoch 20: 0.9758216763814821\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.02\n",
    "weight_decay_movie = 0.3\n",
    "weight_decay_user = 0.3\n",
    "\n",
    "predictor = MatrixFactorizationPredictor(train_data)\n",
    "rng = np.random.default_rng(0)\n",
    "for epoch in range(20):\n",
    "    # Shuffle the dataset\n",
    "    datapoint_indices = rng.permutation(len(train_data.ratings))\n",
    "    for point in datapoint_indices:\n",
    "        movie = train_data.movies[point]\n",
    "        user = train_data.users[point]\n",
    "        rating = train_data.ratings[point]\n",
    "\n",
    "        # Optimize the factorizations in `predictor` using an SGD\n",
    "        # step based on the datapoint (movie, user, rating).\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        user_features = predictor.user_features[user]\n",
    "        movie_features = predictor.movie_features[movie]\n",
    "        err = rating - (user_features * movie_features).sum()\n",
    "        movie_features += learning_rate * (err * user_features - weight_decay_movie * movie_features)\n",
    "        user_features += learning_rate * (err * movie_features - weight_decay_user * user_features)\n",
    "    \n",
    "    learning_rate *= 0.9  # decay the learning rate after each epoch\n",
    "        \n",
    "    print(f\"Train error after epoch {epoch+1}: {mse(predictor(train_data), train_data.ratings)}\")\n",
    "    print(f\"Test error after epoch {epoch+1}: {mse(predictor(test_data), test_data.ratings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect the test error to go down below 1.0.\n",
    "\n",
    "Feel free to play with the weight decay parameters and learning rates to improve these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the factoriziation using Alternating Least Squares\n",
    "\n",
    "Instead of optimizing the objective\n",
    "\n",
    "$$\\frac{1}{|T|}\\sum_{(i, j, r) \\in T} (\\mathbf{m}_i \\cdot \\mathbf{u}_j - r)^2 + \\lambda_\\text{movie} \\left\\lVert \\mathbf{M} \\right\\rVert^2_\\text{F} + \\lambda_\\text{user} \\left\\lVert \\mathbf{U} \\right\\rVert^2_\\text{F}$$\n",
    "\n",
    "using SGD by sampling terms, we can also use ‘Alternating Least Squares’. For ALS, we make the observation that, if all users representations $\\mathbf{u}_j$ are fixed, optimizing all $\\mathbf{m}_i$ is a simple least squares problem. Similarly, if the movie representations $\\mathbf{m}_i$ are all fixed, optimizing all $\\mathbf{u}_j$ is a simple least squares problem. \n",
    "\n",
    "What we will do here, is alternate between the following steps:\n",
    "- Fix the user representations, and perfectly optimize the movie representations.\n",
    "- Fix the movie representations, and perfectly optimize the user representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error after step 1: 4.2795331256791895\n",
      "Test error after step 1: 5.102430270237264\n",
      "Train error after step 2: 1.1932472707800694\n",
      "Test error after step 2: 1.3986097947816118\n",
      "Train error after step 3: 0.9855487724785074\n",
      "Test error after step 3: 1.1496391854680805\n",
      "Train error after step 4: 0.89804499280623\n",
      "Test error after step 4: 1.0506121953125507\n",
      "Train error after step 5: 0.8574256721668727\n",
      "Test error after step 5: 1.0062031489713594\n",
      "Train error after step 6: 0.8360784488703844\n",
      "Test error after step 6: 0.9839060950439644\n",
      "Train error after step 7: 0.8234798339164903\n",
      "Test error after step 7: 0.9715267097203486\n",
      "Train error after step 8: 0.8153475190130608\n",
      "Test error after step 8: 0.9640884654623993\n",
      "Train error after step 9: 0.809749981168294\n",
      "Test error after step 9: 0.959352373664623\n",
      "Train error after step 10: 0.8057310417941409\n",
      "Test error after step 10: 0.956211197941307\n",
      "Train error after step 11: 0.8027671605229693\n",
      "Test error after step 11: 0.9540680352069968\n",
      "Train error after step 12: 0.8005409707543647\n",
      "Test error after step 12: 0.9525779321358809\n",
      "Train error after step 13: 0.7988452598453144\n",
      "Test error after step 13: 0.9515301057300664\n",
      "Train error after step 14: 0.79753875279775\n",
      "Test error after step 14: 0.9507892652027738\n",
      "Train error after step 15: 0.7965224320069859\n",
      "Test error after step 15: 0.9502647938319213\n",
      "Train error after step 16: 0.7957253440727186\n",
      "Test error after step 16: 0.9498940410469678\n",
      "Train error after step 17: 0.7950956924303382\n",
      "Test error after step 17: 0.9496328475703733\n",
      "Train error after step 18: 0.7945950975429754\n",
      "Test error after step 18: 0.9494497904513209\n",
      "Train error after step 19: 0.7941947734511053\n",
      "Test error after step 19: 0.9493224255224628\n",
      "Train error after step 20: 0.7938728947311225\n",
      "Test error after step 20: 0.9492347026501968\n",
      "Train error after step 21: 0.793612743659228\n",
      "Test error after step 21: 0.9491751391824841\n",
      "Train error after step 22: 0.7934013935086195\n",
      "Test error after step 22: 0.9491355164546174\n",
      "Train error after step 23: 0.7932287673722349\n",
      "Test error after step 23: 0.9491099480895259\n",
      "Train error after step 24: 0.7930869594300226\n",
      "Test error after step 24: 0.9490942149159483\n",
      "Train error after step 25: 0.7929697384142632\n",
      "Test error after step 25: 0.9490852909944578\n",
      "Train error after step 26: 0.7928721777128421\n",
      "Test error after step 26: 0.949081006125479\n"
     ]
    }
   ],
   "source": [
    "movie_regularization = 20\n",
    "user_regularization = 20\n",
    "max_iterations = 1000\n",
    "stop_criterion = 1e-4\n",
    "\n",
    "predictor = MatrixFactorizationPredictor(train_data)\n",
    "user_features = predictor.user_features\n",
    "movie_features = predictor.movie_features\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "prev_train_error = None\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "\n",
    "    # Optimize the user features\n",
    "    for user in np.unique(train_data.users):\n",
    "        # Update `user_features[user]` by optimizing the regularized corresponding least squares objective\n",
    "        mask = train_data.users == user\n",
    "        user_movies = train_data.movies[mask]\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        M = movie_features[user_movies]\n",
    "        r = train_data.ratings[mask]\n",
    "        user_features[user] = np.linalg.solve(M.T @ M + np.eye(M.shape[1]) * user_regularization, M.T @ r)\n",
    "    \n",
    "    # Optimize the movie features using least squares\n",
    "    for movie in np.unique(train_data.movies):\n",
    "        # Update `movie_features[movie]` by optimizing the regularized corresponding least squares objective\n",
    "        mask = train_data.movies == movie\n",
    "        movie_users = train_data.users[mask]\n",
    "        ####################################\n",
    "        ### ___ Enter your code here ___ ###\n",
    "        ####################################\n",
    "        M = user_features[movie_users]\n",
    "        r = train_data.ratings[mask]\n",
    "        movie_features[movie] = np.linalg.solve(M.T @ M + np.eye(M.shape[1]) * movie_regularization, M.T @ r)\n",
    "        \n",
    "    train_error = mse(predictor(train_data), train_data.ratings)\n",
    "    print(f\"Train error after step {iteration+1}: {train_error}\")\n",
    "    print(f\"Test error after step {iteration+1}: {mse(predictor(test_data), test_data.ratings)}\")\n",
    "    \n",
    "    # Stop if the training error is not going down more than 'stop_criterion'\n",
    "    ####################################\n",
    "    ### ___ Enter your code here ___ ###\n",
    "    ####################################\n",
    "    if prev_train_error is not None and np.abs(train_error - prev_train_error) < stop_criterion:\n",
    "        break\n",
    "    prev_train_error = train_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that this beats the simple baselines.\n",
    "Using default SGD parameters, the alternating least squares solution here outperforms it, but by tuning SGD carefully, you should be able to get the same quality."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
